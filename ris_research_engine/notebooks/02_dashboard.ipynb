{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIS Auto-Research Engine - Interactive Dashboard\n",
    "\n",
    "This notebook demonstrates the **RISDashboard** - a powerful interactive GUI for configuring, running, and analyzing RIS experiments. The dashboard provides 5 tabs for complete experiment management:\n",
    "\n",
    "1. **Configure** - Set up experiment parameters\n",
    "2. **Run** - Execute experiments and monitor progress\n",
    "3. **Results** - View individual experiment results\n",
    "4. **Analyze** - Compare and visualize multiple experiments\n",
    "5. **Export** - Save results and generate reports\n",
    "\n",
    "**Best for:** Interactive exploration, parameter tuning, and quick prototyping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import and Initialize\n",
    "\n",
    "Import the dashboard class and create an instance. The dashboard will connect to your results database and prepare all interactive widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress widget warnings\n",
    "\n",
    "from ris_research_engine.ui import RISDashboard\n",
    "\n",
    "# Initialize dashboard\n",
    "dashboard = RISDashboard(db_path=\"results.db\")\n",
    "\n",
    "print(\"âœ“ Dashboard initialized successfully!\")\n",
    "print(\"  Run the next cell to launch the interactive interface.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Launch Interactive Dashboard\n",
    "\n",
    "Execute this cell to display the full dashboard interface. You'll see 5 tabs with interactive controls for managing your research experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dashboard\n",
    "dashboard.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dashboard Usage Guide\n",
    "\n",
    "### Tab 1: Configure Experiments\n",
    "\n",
    "**System Parameters:**\n",
    "- **N (elements)**: Number of RIS elements (16-256). Typical: 64\n",
    "- **K (codebook)**: Codebook size (16-256). Typical: 64\n",
    "- **M (measurements)**: Sensing budget (2-64). Typical: 8-32\n",
    "- **Frequency (GHz)**: Operating frequency (1-100). Standard: 28 GHz\n",
    "- **SNR (dB)**: Signal-to-noise ratio (-10 to 40). Typical: 20 dB\n",
    "\n",
    "**Probe Selection:**\n",
    "- `dft_beams` - DFT-based beamforming (structured)\n",
    "- `hadamard` - Hadamard matrix probes (orthogonal)\n",
    "- `sobol` - Sobol quasi-random sequences\n",
    "- `halton` - Halton quasi-random sequences\n",
    "- `random_uniform` - Uniform random phases (baseline)\n",
    "- `random_binary` - Binary random phases\n",
    "\n",
    "**Model Selection:**\n",
    "- `mlp` - Multi-layer perceptron (simple, fast)\n",
    "- `cnn_1d` - 1D convolutional network (spatial patterns)\n",
    "- `transformer` - Attention-based model (complex, slower)\n",
    "\n",
    "**Training Parameters:**\n",
    "- **Epochs**: Maximum training iterations (10-500)\n",
    "- **Batch Size**: Samples per gradient update (16-256)\n",
    "- **Learning Rate**: Step size for optimization (1e-5 to 1e-2)\n",
    "- **Data Samples**: Training dataset size (100-10000)\n",
    "\n",
    "**Actions:**\n",
    "- Click **\"Add to Queue\"** to add configured experiment\n",
    "- Click **\"Load Config\"** to import from YAML file\n",
    "- View current queue size in the status display\n",
    "\n",
    "---\n",
    "\n",
    "### Tab 2: Run Experiments\n",
    "\n",
    "**Queue Management:**\n",
    "- View all queued experiments with their parameters\n",
    "- See estimated total runtime\n",
    "- Clear queue if needed\n",
    "\n",
    "**Execution:**\n",
    "- Click **\"Run Queue\"** to start sequential execution\n",
    "- Monitor real-time progress with status updates\n",
    "- See live metrics as experiments complete\n",
    "- View error messages if experiments fail\n",
    "\n",
    "**Campaign Mode:**\n",
    "- Load and run predefined search space configs\n",
    "- Select from dropdown (quick_test, probe_comparison, etc.)\n",
    "- Click **\"Run Campaign\"** to execute all experiments\n",
    "\n",
    "**Progress Tracking:**\n",
    "- Current experiment name and status\n",
    "- Completed / Total experiments counter\n",
    "- Estimated time remaining\n",
    "- Latest metrics display\n",
    "\n",
    "---\n",
    "\n",
    "### Tab 3: View Results\n",
    "\n",
    "**Experiment Browser:**\n",
    "- Dropdown to select any completed experiment\n",
    "- Filter by campaign, date, or status\n",
    "- Search by experiment name\n",
    "\n",
    "**Result Display:**\n",
    "- Configuration summary (probe, model, system params)\n",
    "- Final metrics table (accuracy, loss, time)\n",
    "- Training history plots (loss and accuracy curves)\n",
    "- Model architecture details\n",
    "- Convergence statistics\n",
    "\n",
    "**Actions:**\n",
    "- Click **\"Refresh\"** to update experiment list\n",
    "- Click **\"Export Result\"** to save as JSON/CSV\n",
    "- Click **\"View Logs\"** to see detailed execution logs\n",
    "\n",
    "---\n",
    "\n",
    "### Tab 4: Analyze Campaigns\n",
    "\n",
    "**Campaign Selection:**\n",
    "- Choose from available campaigns in database\n",
    "- View campaign metadata (total experiments, date range)\n",
    "\n",
    "**Comparison Plots:**\n",
    "- **Bar Chart**: Compare final metrics across experiments\n",
    "- **Line Plot**: Training curves for all experiments\n",
    "- **Scatter Plot**: Accuracy vs. time trade-offs\n",
    "- **Box Plot**: Metric distributions\n",
    "\n",
    "**Statistical Analysis:**\n",
    "- Mean, median, std dev for each metric\n",
    "- Min/max values with experiment names\n",
    "- Ranking table sorted by primary metric\n",
    "- Confidence intervals (if multiple seeds)\n",
    "\n",
    "**Filters:**\n",
    "- Filter by probe type\n",
    "- Filter by model type\n",
    "- Filter by status (completed/failed)\n",
    "- Date range selection\n",
    "\n",
    "---\n",
    "\n",
    "### Tab 5: Export Data\n",
    "\n",
    "**Export Formats:**\n",
    "- **CSV**: Tabular data for Excel/pandas\n",
    "- **JSON**: Full experiment details with nested data\n",
    "- **LaTeX**: Tables ready for papers\n",
    "- **Markdown**: Reports for documentation\n",
    "\n",
    "**Report Generation:**\n",
    "- Click **\"Generate PDF Report\"** for complete analysis\n",
    "- Includes all plots, tables, and summaries\n",
    "- Saved to `outputs/reports/` directory\n",
    "\n",
    "**Batch Export:**\n",
    "- Select multiple experiments to export\n",
    "- Choose format and destination\n",
    "- Download ZIP file with all results\n",
    "\n",
    "**Database Backup:**\n",
    "- Export entire database to JSON\n",
    "- Create timestamped backup\n",
    "- Import from previous backups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick Start Example\n",
    "\n",
    "Here's a simple workflow to get started:\n",
    "\n",
    "### Step-by-Step:\n",
    "\n",
    "1. **Configure** (Tab 1):\n",
    "   - Set N=64, K=64, M=8\n",
    "   - Select probe: `hadamard`\n",
    "   - Select model: `mlp`\n",
    "   - Set epochs=50, batch_size=64\n",
    "   - Click \"Add to Queue\"\n",
    "   \n",
    "2. **Add Baseline** (Tab 1):\n",
    "   - Change probe to `random_uniform`\n",
    "   - Keep other settings\n",
    "   - Click \"Add to Queue\"\n",
    "   \n",
    "3. **Run** (Tab 2):\n",
    "   - Verify 2 experiments in queue\n",
    "   - Click \"Run Queue\"\n",
    "   - Wait ~2-3 minutes\n",
    "   \n",
    "4. **View Results** (Tab 3):\n",
    "   - Select each experiment from dropdown\n",
    "   - Compare training curves\n",
    "   - Note accuracy differences\n",
    "   \n",
    "5. **Analyze** (Tab 4):\n",
    "   - View side-by-side comparison\n",
    "   - Generate bar chart\n",
    "   - Export comparison table\n",
    "   \n",
    "6. **Export** (Tab 5):\n",
    "   - Select CSV format\n",
    "   - Click \"Export Results\"\n",
    "   - Open in Excel/pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tips and Troubleshooting\n",
    "\n",
    "### Performance Tips:\n",
    "\n",
    "- **Start Small**: Use N=16, K=16, M=4 for initial testing\n",
    "- **Quick Validation**: Set epochs=10 to verify pipeline\n",
    "- **Batch Processing**: Queue multiple experiments to run overnight\n",
    "- **GPU Acceleration**: Dashboard automatically uses GPU if available\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "**Widgets Not Displaying:**\n",
    "```bash\n",
    "# Install ipywidgets and enable extension\n",
    "pip install ipywidgets\n",
    "jupyter nbextension enable --py widgetsnbextension\n",
    "```\n",
    "\n",
    "**Dashboard Freezes:**\n",
    "- Long-running experiments may appear frozen\n",
    "- Check console output for progress\n",
    "- Use Tab 2 status display for live updates\n",
    "\n",
    "**Memory Issues:**\n",
    "- Reduce `data_samples` (try 1000)\n",
    "- Decrease `batch_size` (try 32)\n",
    "- Lower N and K values\n",
    "\n",
    "**Cannot Load Config:**\n",
    "- Verify YAML file path is correct\n",
    "- Check file has proper YAML syntax\n",
    "- See example configs in `../configs/search_spaces/`\n",
    "\n",
    "### Advanced Features:\n",
    "\n",
    "**Programmatic Access:**\n",
    "```python\n",
    "# Access underlying engine\n",
    "engine = dashboard.engine\n",
    "\n",
    "# Get queue status\n",
    "queue_size = len(dashboard.queue)\n",
    "\n",
    "# Clear specific experiment\n",
    "dashboard.queue.pop(0)\n",
    "```\n",
    "\n",
    "**Custom Callbacks:**\n",
    "```python\n",
    "# Add callback for experiment completion\n",
    "def on_complete(result):\n",
    "    print(f\"Experiment {result['config']['name']} completed!\")\n",
    "    \n",
    "dashboard.register_callback(on_complete)\n",
    "```\n",
    "\n",
    "### Need Help?\n",
    "\n",
    "- Check documentation: `docs/user_guide.md`\n",
    "- View examples: `examples/` directory\n",
    "- Report issues: GitHub Issues\n",
    "- API reference: `docs/api/`\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Try **03_run_search.ipynb** for predefined campaigns\n",
    "- Explore **04_analyze_results.ipynb** for advanced analysis\n",
    "- Read **01_quickstart.ipynb** for API basics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
