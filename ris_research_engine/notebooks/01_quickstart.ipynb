{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIS Auto-Research Engine - Quick Start Guide\n",
    "\n",
    "This notebook provides a quick introduction to the RIS Auto-Research Engine. You'll learn how to:\n",
    "- Verify your installation\n",
    "- Run your first experiments\n",
    "- Visualize and compare results\n",
    "\n",
    "**Expected Runtime:** ~2-3 minutes for the quick test campaign (2 experiments).\n",
    "\n",
    "**Prerequisites:** Make sure you've installed the package with `pip install -e .` from the repository root."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation Check\n",
    "\n",
    "First, let's verify that all required modules are properly installed and can be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core modules\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Import RIS Engine components\n",
    "try:\n",
    "    from ris_research_engine.ui import RISEngine\n",
    "    from ris_research_engine.foundation import __version__\n",
    "    from ris_research_engine.plugins.probes import list_probes\n",
    "    from ris_research_engine.plugins.models import list_models\n",
    "    print(\"‚úì RIS Research Engine successfully imported!\")\n",
    "    print(f\"  Version: {__version__ if '__version__' in dir() else 'development'}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚úó Import error: {e}\")\n",
    "    print(\"  Please install the package: pip install -e .\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Check Python version\n",
    "print(f\"\\n‚úì Python version: {sys.version.split()[0]}\")\n",
    "print(f\"‚úì NumPy version: {np.__version__}\")\n",
    "print(f\"‚úì Pandas version: {pd.__version__}\")\n",
    "print(f\"‚úì Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "\n",
    "# List available probes and models\n",
    "print(\"\\nAvailable Probes:\")\n",
    "for probe in list_probes():\n",
    "    print(f\"  - {probe}\")\n",
    "\n",
    "print(\"\\nAvailable Models:\")\n",
    "for model in list_models():\n",
    "    print(f\"  - {model}\")\n",
    "\n",
    "print(\"\\n‚úì All components ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize RIS Engine\n",
    "\n",
    "Create an instance of the RISEngine with default settings. Results will be stored in `results.db` and outputs saved to `outputs/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize engine\n",
    "engine = RISEngine(\n",
    "    db_path=\"results.db\",\n",
    "    output_dir=\"outputs\"\n",
    ")\n",
    "\n",
    "print(\"RIS Engine initialized successfully!\")\n",
    "print(f\"  Database: {engine.db_path}\")\n",
    "print(f\"  Output directory: {engine.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Quick Test Campaign\n",
    "\n",
    "Run the `quick_test.yaml` configuration which includes 2 experiments:\n",
    "- Hadamard probe (expected best performance)\n",
    "- Random uniform probe (baseline)\n",
    "\n",
    "This campaign uses small system parameters (N=16, K=16, M=4) and only 10 epochs for fast validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to quick test configuration\n",
    "config_path = \"../configs/search_spaces/quick_test.yaml\"\n",
    "\n",
    "# Run the campaign\n",
    "print(\"Starting quick test campaign...\\n\")\n",
    "try:\n",
    "    campaign_result = engine.search(config_path)\n",
    "    print(\"\\n‚úì Campaign completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚úó Campaign failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Display Results Table\n",
    "\n",
    "View a summary of all experiments in a clean tabular format showing key metrics and configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract experiment results\n",
    "experiments = campaign_result['experiments']\n",
    "\n",
    "# Create summary table\n",
    "results_data = []\n",
    "for exp in experiments:\n",
    "    results_data.append({\n",
    "        'Experiment': exp['config']['name'],\n",
    "        'Probe': exp['config']['probe_type'],\n",
    "        'Model': exp['config']['model_type'],\n",
    "        'Status': exp['status'],\n",
    "        'Top-1 Acc': f\"{exp['metrics'].get('top_1_accuracy', 0):.3f}\",\n",
    "        'Val Loss': f\"{exp['metrics'].get('val_loss', 0):.4f}\",\n",
    "        'Time (s)': f\"{exp['training_time_seconds']:.1f}\",\n",
    "        'Epochs': exp['total_epochs']\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPERIMENT RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot Training Curves\n",
    "\n",
    "Visualize the training and validation loss curves for both experiments to understand convergence behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid' if 'seaborn-v0_8-darkgrid' in plt.style.available else 'default')\n",
    "\n",
    "# Create subplots for each experiment\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('Training Curves - Quick Test Campaign', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, exp in enumerate(experiments):\n",
    "    if 'training_history' in exp:\n",
    "        history = exp['training_history']\n",
    "        epochs = range(1, len(history['train_loss']) + 1)\n",
    "        \n",
    "        # Plot on subplot\n",
    "        ax = axes[idx]\n",
    "        ax.plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "        if 'val_loss' in history:\n",
    "            ax.plot(epochs, history['val_loss'], 'r--', label='Val Loss', linewidth=2)\n",
    "        \n",
    "        ax.set_xlabel('Epoch', fontsize=11)\n",
    "        ax.set_ylabel('Loss', fontsize=11)\n",
    "        ax.set_title(f\"{exp['config']['probe_type']}\", fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Training curves plotted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Accuracy Comparison\n",
    "\n",
    "Compare validation accuracy across epochs for both probe types to see which converges faster and achieves better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for exp in experiments:\n",
    "    if 'training_history' in exp:\n",
    "        history = exp['training_history']\n",
    "        if 'val_top_1_accuracy' in history:\n",
    "            epochs = range(1, len(history['val_top_1_accuracy']) + 1)\n",
    "            ax.plot(epochs, history['val_top_1_accuracy'], \n",
    "                   marker='o', linewidth=2.5, markersize=6,\n",
    "                   label=exp['config']['probe_type'])\n",
    "\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Top-1 Accuracy', fontsize=12)\n",
    "ax.set_title('Validation Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Accuracy comparison plotted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Show Baseline Comparison\n",
    "\n",
    "Display final metrics side-by-side to compare probe performance. Hadamard probes typically outperform random probes due to their structured design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare final metrics\n",
    "comparison_data = []\n",
    "for exp in experiments:\n",
    "    comparison_data.append({\n",
    "        'Probe Type': exp['config']['probe_type'],\n",
    "        'Top-1 Accuracy': exp['metrics'].get('top_1_accuracy', 0),\n",
    "        'Top-5 Accuracy': exp['metrics'].get('top_5_accuracy', 0),\n",
    "        'Val Loss': exp['metrics'].get('val_loss', 0),\n",
    "        'Training Time (s)': exp['training_time_seconds'],\n",
    "        'Model Params': exp['model_parameters']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Format for display\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROBE COMPARISON - FINAL METRICS\")\n",
    "print(\"=\"*80)\n",
    "for col in ['Top-1 Accuracy', 'Top-5 Accuracy', 'Val Loss']:\n",
    "    comparison_df[col] = comparison_df[col].apply(lambda x: f\"{x:.4f}\")\n",
    "comparison_df['Training Time (s)'] = comparison_df['Training Time (s)'].apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Determine winner\n",
    "best_idx = comparison_df['Top-1 Accuracy'].astype(float).idxmax()\n",
    "best_probe = comparison_data[best_idx]['Probe Type']\n",
    "print(f\"\\nüèÜ Best Probe: {best_probe}\")\n",
    "print(f\"   Top-1 Accuracy: {comparison_data[best_idx]['Top-1 Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "**Congratulations!** You've successfully:\n",
    "- ‚úì Verified your RIS Engine installation\n",
    "- ‚úì Run your first experiment campaign\n",
    "- ‚úì Visualized training curves and accuracy metrics\n",
    "- ‚úì Compared probe performance\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Interactive Dashboard** ‚Üí Try `02_dashboard.ipynb` for a full GUI experience with 5 tabs\n",
    "2. **Run Larger Campaigns** ‚Üí Explore `03_run_search.ipynb` for comprehensive search spaces\n",
    "3. **Deep Analysis** ‚Üí Use `04_analyze_results.ipynb` for statistical analysis and reporting\n",
    "\n",
    "### Available Campaigns:\n",
    "- `quick_test.yaml` - Fast validation (2 experiments, ~2 min) ‚Üê You just ran this!\n",
    "- `probe_comparison.yaml` - Compare 6 probe types (18 experiments, ~15 min)\n",
    "- `model_comparison.yaml` - Compare 3 model architectures (9 experiments, ~10 min)\n",
    "- `sparsity_sweep.yaml` - Optimize sparsity parameter (45 experiments, ~30 min)\n",
    "- `full_search.yaml` - Comprehensive search (200+ experiments, several hours)\n",
    "\n",
    "### Customization:\n",
    "You can also run individual experiments programmatically:\n",
    "```python\n",
    "result = engine.run(\n",
    "    probe='hadamard',\n",
    "    model='mlp',\n",
    "    M=8, K=64, N=64,\n",
    "    epochs=100\n",
    ")\n",
    "engine.show(result)\n",
    "```\n",
    "\n",
    "Happy researching! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
